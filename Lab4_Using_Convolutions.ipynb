{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Lab4-Using-Convolutions.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Julia-Vanyarina/neiro/blob/main/Lab4_Using_Convolutions.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "R6gHiH-I7uFa"
      },
      "cell_type": "markdown",
      "source": [
        "# Повышение точности компьютерного зрения с помощью свертки\n",
        "\n",
        "В предыдущих уроках вы видели, как выполнять распознавание моды с использованием глубокой нейронной сети (DNN), содержащей три слоя: входной слой (в форме данных), выходной слой (в форме желаемого результата) и скрытый слой. Вы экспериментировали с влиянием разного размера скрытого слоя, количества эпох обучения и т.д. На конечную точность.\n",
        "\n",
        "Для удобства приведем еще раз весь код. Запустите его и обратите внимание на точность теста, которая распечатана в конце."
      ]
    },
    {
      "metadata": {
        "id": "xcsRtq9OLorS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a28ff4d1-59ed-4ef7-a3c3-bc3cdd8a0bb0"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images / 255.0\n",
        "test_images=test_images / 255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation=tf.nn.relu),\n",
        "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "\n",
        "test_loss = model.evaluate(test_images, test_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 3ms/step - accuracy: 0.7788 - loss: 0.6315\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 4ms/step - accuracy: 0.8629 - loss: 0.3844\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 3ms/step - accuracy: 0.8763 - loss: 0.3363\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 4ms/step - accuracy: 0.8839 - loss: 0.3159\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.8903 - loss: 0.2936\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - accuracy: 0.8594 - loss: 0.3836\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "zldEXSsF8Noz"
      },
      "cell_type": "markdown",
      "source": [
        "Ваша точность, вероятно, составляет около 89% при обучении и 87% при проверке ... неплохо ... Но как сделать это еще лучше? Один из способов - использовать нечто, называемое свертками. Я не буду здесь вдаваться в подробности о свертках, но конечная концепция заключается в том, что они сужают содержание изображения, фокусируясь на конкретных, отчетливых деталях.\n",
        "\n",
        "Если вы когда-либо обрабатывали изображения с помощью фильтра (например, этого: https://en.wikipedia.org/wiki/Kernel_ (image_processing)), то свертки будут выглядеть очень знакомо.\n",
        "\n",
        "... тогда требуется гораздо меньше информации...потому что вы будете просто тренироваться на выделенных функциях.\n",
        "\n",
        "Это концепция сверточных нейронных сетей. Добавьте несколько слоев для выполнения свертки до того, как у вас появятся плотные слои, и тогда информация, поступающая в плотные слои, будет более сфокусированной и, возможно, более точной.\n",
        "\n",
        "Запустите приведенный ниже код - это та же нейронная сеть, что и ранее, но на этот раз сначала добавлены сверточные слои. Это займет больше времени, но посмотрите на влияние на точность:"
      ]
    },
    {
      "metadata": {
        "id": "C0tFgT1MMKi6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 630
        },
        "outputId": "768d46ff-c654-4da2-da2e-32cbb6da73fa"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.summary()\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss = model.evaluate(test_images, test_labels)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │             \u001b[38;5;34m640\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m11\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │          \u001b[38;5;34m36,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m5\u001b[0m, \u001b[38;5;34m64\u001b[0m)            │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1600\u001b[0m)                │               \u001b[38;5;34m0\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │         \u001b[38;5;34m204,928\u001b[0m │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m10\u001b[0m)                  │           \u001b[38;5;34m1,290\u001b[0m │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
              "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">640</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">11</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │          <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)            │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1600</span>)                │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │         <span style=\"color: #00af00; text-decoration-color: #00af00\">204,928</span> │\n",
              "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
              "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">10</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">1,290</span> │\n",
              "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m243,786\u001b[0m (952.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243,786</span> (952.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m243,786\u001b[0m (952.29 KB)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">243,786</span> (952.29 KB)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m88s\u001b[0m 46ms/step - accuracy: 0.7794 - loss: 0.6037\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 45ms/step - accuracy: 0.8885 - loss: 0.2994\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m87s\u001b[0m 46ms/step - accuracy: 0.9078 - loss: 0.2488\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m144s\u001b[0m 47ms/step - accuracy: 0.9200 - loss: 0.2115\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m140s\u001b[0m 46ms/step - accuracy: 0.9310 - loss: 0.1833\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 16ms/step - accuracy: 0.9050 - loss: 0.2792\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "uRLfZ0jt-fQI"
      },
      "cell_type": "markdown",
      "source": [
        "Вероятно, он вырос примерно до 93% для обучающих данных и 91% для данных проверки.\n",
        "\n",
        "Это важно и шаг в правильном направлении!\n",
        "\n",
        "Попробуйте запустить его еще несколько эпох - скажем, около 20, и ознакомьтесь с результатами! Но хотя результаты могут показаться действительно хорошими, на самом деле результаты проверки могут ухудшиться из-за так называемого \"переоснащения\", которое будет обсуждаться позже.\n",
        "\n",
        "(В двух словах, \"переобучение\" происходит, когда сеть действительно хорошо изучает данные из обучающего набора, но она слишком специализирована только на этих данных и, как следствие, менее эффективна при просмотре * других * данных. Например, если всю свою жизнь вы видели только красные туфли, то, увидев красную обувь, вы бы очень хорошо ее опознали, но синие замшевые туфли могут вас смутить ... и вы знаете, что вам никогда не следует связываться с моими синими замшевыми туфлями.)\n",
        "\n",
        "Затем взгляните на код еще раз и посмотрите, шаг за шагом, как были построены свертки:"
      ]
    },
    {
      "metadata": {
        "id": "RaLX5cgI_JDb"
      },
      "cell_type": "markdown",
      "source": [
        "Шаг 1 - собрать данные. Вы заметите, что здесь есть небольшое изменение в том, что данные обучения необходимо изменить. Это потому, что первая свертка ожидает единый тензор, содержащий все, поэтому вместо 60 000 элементов 28x28x1 в списке у нас есть единый список 4D размером 60 000x28x28x1, и то же самое для тестовых изображений. Если вы этого не сделаете, вы получите сообщение об ошибке при обучении, поскольку свертки не распознают форму.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "```\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "mnist = tf.keras.datasets.fashion_mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "   tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s0iUuTPW8wjc",
        "outputId": "ee6af41c-9b15-4b40-cab0-3fcd2febf148"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 29ms/step - accuracy: 0.7685 - loss: 0.6417\n",
            "Epoch 2/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 29ms/step - accuracy: 0.8871 - loss: 0.3096\n",
            "Epoch 3/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m82s\u001b[0m 29ms/step - accuracy: 0.9072 - loss: 0.2548\n",
            "Epoch 4/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - accuracy: 0.9176 - loss: 0.2211\n",
            "Epoch 5/5\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 29ms/step - accuracy: 0.9283 - loss: 0.1949\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 11ms/step - accuracy: 0.8988 - loss: 0.2926\n",
            "0.9014999866485596\n"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "SS_W_INc_kJQ"
      },
      "cell_type": "markdown",
      "source": [
        "Далее необходимо определить вашу модель. Теперь вместо входного слоя вверху вы собираетесь добавить свертку. Параметры следующие::\n",
        "\n",
        "1. Количество свертков, которые вы хотите сгенерировать. Чисто произвольный, но хорошо бы начать с чего-нибудь порядка 32\n",
        "2. Размер свертки, в данном случае сетки 3x3\n",
        "3. Используемая функция активации - в этом случае мы будем использовать relu, которая, как вы помните, эквивалентна возврату x, когда x> 0, в противном случае возвращается 0\n",
        "4. На первом слое - форма входных данных.\n",
        "\n",
        "... вы заметите, что после каждого слоя MaxPooling размер изображения уменьшается таким образом.\n",
        "\n",
        "\n",
        "```\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "RMorM6daADjA"
      },
      "cell_type": "markdown",
      "source": [
        "Добавьте еще одну свертку\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "b1-x-kZF4_tC"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь сгладьте выходные данные. После этого у вас будет та же структура DNN, что и в несверточной версии\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Flatten(),\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "qPtqR23uASjX"
      },
      "cell_type": "markdown",
      "source": [
        "Те же 128 плотных слоев и 10 выходных слоев, что и в примере предварительной свертки:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "```\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "C0GSsjUhAaSj"
      },
      "cell_type": "markdown",
      "source": [
        "Теперь скомпилируйте модель, вызовите метод fit для выполнения обучения и оцените потери и точность по тестовому набору.\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=5)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)\n",
        "```\n",
        "\n",
        "\n"
      ]
    },
    {
      "metadata": {
        "id": "IXx_LX3SAlFs"
      },
      "cell_type": "markdown",
      "source": [
        "# Визуализация сверток и объединение в пул\n",
        "\n",
        "Этот код покажет нам свертки графически. Печать (test_labels[;100]) показывает нам первые 100 меток в тестовом наборе, и вы можете видеть, что все метки с индексом 0, индексом 23 и индексом 28 имеют одинаковое значение (9). Все они представляют собой ботинки. Давайте посмотрим на результат выполнения свертки для каждого из них, и вы начнете замечать, что между ними появляются общие черты. Теперь, когда DNN обучается на этих данных, он работает с гораздо меньшим объемом данных и, возможно, находит общность между shoes на основе этой комбинации свертки / объединения."
      ]
    },
    {
      "metadata": {
        "id": "f-6nX4QsOku6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "73d4ba13-b8af-408f-e5a4-63fa462c3d8f"
      },
      "cell_type": "code",
      "source": [
        "print(test_labels[:100])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9 2 1 1 6 1 4 6 5 7 4 5 7 3 4 1 2 4 8 0 2 5 7 9 1 4 6 0 9 3 8 8 3 3 8 0 7\n",
            " 5 7 9 6 1 3 7 6 7 2 1 2 2 4 4 5 8 2 2 8 4 8 0 7 7 8 5 1 1 2 3 9 8 7 0 2 6\n",
            " 2 3 1 2 8 4 1 8 5 9 5 0 3 2 0 6 5 3 6 7 1 8 0 1 4 2]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1. Загрузка и подготовка данных MNIST\n",
        "python\n",
        "Copy\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "Загружаем стандартный датасет MNIST (рукописные цифры)\n",
        "\n",
        "Изменяем форму тестовых изображений (10000 примеров, 28x28 пикселей, 1 канал - ч/б)\n",
        "\n",
        "Нормализуем значения пикселей в диапазон [0,1]\n",
        "\n",
        "2. Создание модели с помощью Functional API\n",
        "python\n",
        "Copy\n",
        "input_layer = tf.keras.layers.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer)\n",
        "...\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "Явно определяем входной слой с формой (28,28,1)\n",
        "\n",
        "Последовательно добавляем слои свертки, пулинга и полносвязные слои\n",
        "\n",
        "Создаем модель, явно указывая входы и выходы\n",
        "\n",
        "3. Создание модели для визуализации активаций\n",
        "python\n",
        "Copy\n",
        "layer_outputs = [layer.output for layer in model.layers[1:]]  # Пропускаем входной слой\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "Собираем выходы всех слоев (кроме входного)\n",
        "\n",
        "Создаем новую модель, которая будет возвращать активации всех слоев\n",
        "\n",
        "4. Настройка визуализации\n",
        "python\n",
        "Copy\n",
        "f, axarr = plt.subplots(3, 4, figsize=(12, 8))\n",
        "Создаем сетку графиков 3 строки × 4 столбца\n",
        "\n",
        "5. Визуализация активаций\n",
        "python\n",
        "Copy\n",
        "for x in range(min(4, len(layer_outputs))):\n",
        "    f1 = activation_model.predict(test_images[FIRST_IMAGE][np.newaxis, ...])[x]\n",
        "    if len(f1.shape) == 4:\n",
        "        axarr[0,x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "Для первых 4 слоев (или всех, если их меньше):\n",
        "\n",
        "Получаем активации для трех разных изображений\n",
        "\n",
        "Проверяем, что слой имеет 4D-выход (подходит для визуализации)\n",
        "\n",
        "Отображаем активации определенного фильтра (CONVOLUTION_NUMBER)\n",
        "\n",
        "Настраиваем отображение (убираем оси и сетку)\n",
        "\n",
        "Особенности решения:\n",
        "Functional API вместо Sequential - гарантирует правильное построение модели\n",
        "\n",
        "Проверка размерностей - только 4D тензоры (сверточные слои) визуализируются\n",
        "\n",
        "Обработка ошибок - пропускаем слои, которые нельзя отобразить\n",
        "\n",
        "Гибкость - работает с любым количеством слоев\n",
        "\n",
        "Этот подход надежен, потому что:\n",
        "\n",
        "Модель строится явно с указанием входов/выходов\n",
        "\n",
        "Все слои правильно инициализированы до создания activation_model\n",
        "\n",
        "Код адаптируется под разные архитектуры сетей\n",
        "\n",
        "Результат - визуализация того, как разные слои сети \"видят\" входные изображения."
      ],
      "metadata": {
        "id": "bmMf-C5g5uEA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "# 1. Load and prepare MNIST data\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n",
        "\n",
        "# 2. Define and build the model properly\n",
        "input_layer = tf.keras.layers.Input(shape=(28, 28, 1))\n",
        "x = tf.keras.layers.Conv2D(32, (3,3), activation='relu')(input_layer)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.MaxPooling2D((2, 2))(x)\n",
        "x = tf.keras.layers.Conv2D(64, (3,3), activation='relu')(x)\n",
        "x = tf.keras.layers.Flatten()(x)\n",
        "x = tf.keras.layers.Dense(64, activation='relu')(x)\n",
        "output_layer = tf.keras.layers.Dense(10)(x)\n",
        "\n",
        "model = tf.keras.models.Model(inputs=input_layer, outputs=output_layer)\n",
        "\n",
        "# 3. Alternative way to create activation model\n",
        "layer_outputs = [layer.output for layer in model.layers[1:]]  # Skip input layer\n",
        "activation_model = tf.keras.models.Model(inputs=model.input, outputs=layer_outputs)\n",
        "\n",
        "# 4. Visualization setup\n",
        "f, axarr = plt.subplots(3, 4, figsize=(12, 8))\n",
        "FIRST_IMAGE = 0\n",
        "SECOND_IMAGE = 7\n",
        "THIRD_IMAGE = 26\n",
        "CONVOLUTION_NUMBER = 0  # Changed to 0 as first filter index\n",
        "\n",
        "# 5. Get and display activations\n",
        "for x in range(min(4, len(layer_outputs))):  # For first 4 layers or all if less\n",
        "    try:\n",
        "        # First image\n",
        "        f1 = activation_model.predict(test_images[FIRST_IMAGE][np.newaxis, ...])[x]\n",
        "        if len(f1.shape) == 4:  # Conv/Pool layer\n",
        "            axarr[0, x].imshow(f1[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "        axarr[0, x].grid(False)\n",
        "        axarr[0, x].set_xticks([])\n",
        "        axarr[0, x].set_yticks([])\n",
        "\n",
        "        # Second image\n",
        "        f2 = activation_model.predict(test_images[SECOND_IMAGE][np.newaxis, ...])[x]\n",
        "        if len(f2.shape) == 4:\n",
        "            axarr[1, x].imshow(f2[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "        axarr[1, x].grid(False)\n",
        "        axarr[1, x].set_xticks([])\n",
        "        axarr[1, x].set_yticks([])\n",
        "\n",
        "        # Third image\n",
        "        f3 = activation_model.predict(test_images[THIRD_IMAGE][np.newaxis, ...])[x]\n",
        "        if len(f3.shape) == 4:\n",
        "            axarr[2, x].imshow(f3[0, :, :, CONVOLUTION_NUMBER], cmap='inferno')\n",
        "        axarr[2, x].grid(False)\n",
        "        axarr[2, x].set_xticks([])\n",
        "        axarr[2, x].set_yticks([])\n",
        "    except:\n",
        "        axarr[0, x].axis('off')\n",
        "        axarr[1, x].axis('off')\n",
        "        axarr[2, x].axis('off')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zsEagEawzz9c",
        "outputId": "410a17aa-048a-42f6-8407-d5bed8399a69"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 36ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1200x800 with 12 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "metadata": {
        "id": "8KVPZqgHo5Ux"
      },
      "cell_type": "markdown",
      "source": [
        "УПРАЖНЕНИЯ\n",
        "\n",
        "1. Попробуйте отредактировать свертки. Измените 32 секунды на 16 или 64. Как это повлияет на точность и / или время тренировки.\n",
        "\n",
        "2. Удалите последнюю свертку. Как это повлияет на точность или время обучения?\n",
        "\n",
        "3. Как насчет добавления дополнительных сверток? Как вы думаете, какое влияние это окажет? Поэкспериментируйте с этим.\n",
        "\n",
        "4. Удалите все свертки, кроме первой. Как вы думаете, какое влияние это окажет? Поэкспериментируйте с этим.\n",
        "\n",
        "5. На предыдущем уроке вы реализовали обратный вызов для проверки функции потерь и отмены тренировки, как только она достигнет определенной суммы. Посмотрите, сможете ли вы реализовать это здесь!"
      ]
    },
    {
      "metadata": {
        "id": "ZpYRidBXpBPM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da64ef93-7fca-4979-c93c-5d80f86901ab"
      },
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n",
        "mnist = tf.keras.datasets.mnist\n",
        "(training_images, training_labels), (test_images, test_labels) = mnist.load_data()\n",
        "training_images=training_images.reshape(60000, 28, 28, 1)\n",
        "training_images=training_images / 255.0\n",
        "test_images = test_images.reshape(10000, 28, 28, 1)\n",
        "test_images=test_images/255.0\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(32, (3,3), activation='relu', input_shape=(28, 28, 1)),\n",
        "  tf.keras.layers.MaxPooling2D(2, 2),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "model.fit(training_images, training_labels, epochs=10)\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print(test_acc)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.18.0\n",
            "Epoch 1/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.9150 - loss: 0.2991\n",
            "Epoch 2/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.9836 - loss: 0.0549\n",
            "Epoch 3/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.9907 - loss: 0.0306\n",
            "Epoch 4/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 21ms/step - accuracy: 0.9942 - loss: 0.0198\n",
            "Epoch 5/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 21ms/step - accuracy: 0.9966 - loss: 0.0116\n",
            "Epoch 6/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 20ms/step - accuracy: 0.9974 - loss: 0.0081\n",
            "Epoch 7/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 20ms/step - accuracy: 0.9978 - loss: 0.0063\n",
            "Epoch 8/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.9982 - loss: 0.0055\n",
            "Epoch 9/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "Epoch 10/10\n",
            "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 20ms/step - accuracy: 0.9991 - loss: 0.0031\n",
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.9846 - loss: 0.0625\n",
            "0.9884999990463257\n"
          ]
        }
      ]
    }
  ]
}